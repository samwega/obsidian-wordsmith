{
	"pluginInfo": {
		"id": "wordsmith",
		"name": "WordSmith",
		"version": "3.1.2",
		"description": "An AI-powered writing assistant for Obsidian featuring inline suggestions, contextual content generation, and knowledge graph creation, supporting a wide range of models and providers.",
		"author": "samwega"
	},
	"architecture": {
		"designPrinciples": [
			"Modularity and Separation of Concerns: Logic is clearly divided into Services, UI Components, LLM Handlers, and Editor Integration.",
			"Service-Oriented Architecture: Core functionalities like model fetching, provider management, and favorites are encapsulated in dedicated services (`ModelService`, `CustomProviderService`, `FavoritesService`).",
			"State Management Decoupling: Editor-specific state (suggestions) is managed via a CodeMirror `StateField`, while persistent settings are handled by the main plugin class, and UI state is managed within respective components.",
			"API Abstraction: LLM interactions are routed through specific handlers (`chatCompletionRequest`, `geminiRequest`) and a centralized `prompt-builder`, abstracting away provider-specific details from the core feature logic.",
			"Extensibility: The custom provider system allows users to add new API endpoints without code changes. The prompt management system allows for deep user customization."
		],
		"coreModules": {
			"main": {
				"file": "src/main.ts",
				"description": "The plugin's entry point. Responsible for lifecycle management (`onload`/`onunload`), service initialization, settings management, and registration of all commands, views, and editor extensions."
			},
			"services": {
				"file": "src/services/",
				"description": "Handles background logic, API interactions, and data management, decoupled from the UI.",
				"components": ["ModelService", "CustomProviderService", "FavoritesService"]
			},
			"llmIntegration": {
				"file": "src/llm/",
				"description": "Manages all communication with LLMs, including prompt construction and API-specific request formatting.",
				"components": ["prompt-builder.ts", "chat-completion-handler.ts", "gemini.ts"]
			},
			"coreLogic": {
				"file": "src/lib/core/",
				"description": "Contains the primary business logic for the plugin's main features.",
				"components": ["textTransformer.ts", "graphGenerator.ts"]
			},
			"editorIntegration": {
				"file": "src/lib/editor/",
				"description": "Manages all direct interaction with the CodeMirror 6 editor, primarily for the suggestion system.",
				"components": ["suggestion-state.ts", "suggestion-handler.ts", "paragraph-utils.ts"]
			},
			"userInterface": {
				"file": "src/ui/",
				"description": "Contains all user-facing components, including modals, the settings tab, and the context panel view.",
				"components": ["context-control-panel.ts", "settings.ts", "modals/*.ts"]
			},
			"dataAndConstants": {
				"file": "src/lib/",
				"description": "Defines core data structures, types, constants, and shared utilities.",
				"components": [
					"settings-data.ts",
					"constants.ts",
					"provider-utils.ts",
					"graph/types.ts",
					"utils.ts"
				]
			}
		},
		"dependencyGraph": {
			"main.ts": ["services/*", "ui/*", "lib/core/*", "lib/editor/*"],
			"lib/core/*": [
				"llm/*",
				"lib/editor/suggestion-state.ts",
				"lib/settings-data.ts",
				"ui/context-control-panel.ts"
			],
			"llm/*": ["lib/settings-data.ts", "lib/constants.ts", "lib/core/textTransformer.ts"],
			"services/*": ["main.ts", "lib/settings-data.ts"],
			"ui/*": ["main.ts", "services/*", "lib/settings-data.ts"],
			"lib/editor/suggestion-handler.ts": [
				"lib/editor/suggestion-state.ts",
				"lib/editor/paragraph-utils.ts"
			]
		}
	},
	"dataModel": {
		"settings": {
			"file": "src/lib/settings-data.ts",
			"interface": "TextTransformerSettings",
			"description": "The primary settings object saved to `data.json`. Stores all user configurations.",
			"structure": {
				"customProviders": "Array<CustomProvider>",
				"selectedModelId": "string (e.g., 'openrouter//google/gemini-flash-1.5')",
				"favoriteModels": "Array<FavoriteModel>",
				"temperature": "number",
				"max_tokens": "number",
				"prompts": "Array<TextTransformerPrompt> (for transformations)",
				"generationPrompts": "Array<TextTransformerPrompt> (for generation)",
				"contextToggles": ["useWholeNoteContext", "useCustomContext", "useDynamicContext"],
				"dynamicContextLineCount": "number",
				"customContextText": "string",
				"graphAssetPath": "string"
			}
		},
		"domainModels": [
			{
				"interface": "Model",
				"description": "In-memory representation of an AI model, enriched with provider and favorite status."
			},
			{
				"interface": "CustomProvider",
				"description": "Configuration for a user-defined API provider (e.g., OpenRouter, Ollama)."
			},
			{
				"interface": "FavoriteModel",
				"description": "Schema for storing a favorited model in settings."
			},
			{
				"interface": "TextTransformerPrompt",
				"description": "Defines a reusable prompt with a name, text, and metadata."
			},
			{
				"interface": "SuggestionMark",
				"file": "src/lib/editor/suggestion-state.ts",
				"description": "Represents a single AI-suggested change ('added' or 'removed') within the editor state."
			},
			{
				"interface": "LlmKnowledgeGraph",
				"file": "src/lib/graph/types.ts",
				"description": "The validated structure for the JSON object returned by the LLM for graph generation."
			},
			{
				"interface": "GraphCanvasMetadata",
				"file": "src/lib/graph/types.ts",
				"description": "Metadata embedded as frontmatter in the generated `.canvas` file."
			}
		]
	},
	"stateManagement": {
		"pluginSettings": {
			"mechanism": "Obsidian `loadData`/`saveData` API.",
			"managedBy": "`main.ts` (`loadSettings`, `saveSettings`).",
			"description": "Handles persistence of all user configurations from the `TextTransformerSettings` interface."
		},
		"editorState": {
			"mechanism": "CodeMirror 6 `StateField` (`suggestionStateField`).",
			"managedBy": "`suggestion-state.ts`.",
			"description": "Holds the array of active `SuggestionMark` objects directly within the editor's state, ensuring they are transactional and mapped correctly with document changes."
		},
		"runtimeState": {
			"properties": ["`runtimeDebugMode` in `main.ts`"],
			"description": "Non-persistent state, like the debug flag, held in the main plugin instance."
		}
	},
	"llmIntegration": {
		"promptEngineering": {
			"file": "src/lib/llm/prompt-builder.ts",
			"strategy": "A centralized `buildPromptComponents` function constructs prompts by assembling distinct parts: `systemInstructions`, `userContent`, and a `contextBlock`. This allows for flexible adaptation to different API requirements (e.g., OpenAI vs. Anthropic `system` parameter).",
			"specializedPrompts": {
				"transformation": "Includes the user's instruction and the original text explicitly marked.",
				"generation": "Includes the user's ad-hoc prompt, with context indicating cursor position.",
				"graphGeneration": "Uses a highly specific, detailed prompt with a strict JSON output format specification, examples, and rules."
			}
		},
		"apiHandlers": [
			{
				"name": "OpenAI-Compatible",
				"file": "src/llm/chat-completion-handler.ts",
				"description": "Handles any API that follows the OpenAI `/chat/completions` format. Dynamically constructs the `messages` array, adapting to Anthropic's direct API and other variants. Manages headers (Bearer token, custom OpenRouter headers)."
			},
			{
				"name": "Google Gemini",
				"file": "src/llm/gemini.ts",
				"description": "A dedicated handler for the Google Gemini API, which has a unique endpoint structure (URL includes model and API key) and request/response body format (`contents`, `systemInstruction`, `generationConfig`)."
			}
		],
		"contextAssembly": {
			"file": "src/lib/core/textTransformer.ts (`gatherContextForAI`)",
			"description": "Dynamically assembles the context string based on user settings in the `ContextControlPanel`. It can include dynamic lines around the cursor/selection, the whole note, and custom text. It also resolves `[[wikilinks]]` in the custom context area to embed note content."
		}
	},
	"userInterface": {
		"mainView": {
			"name": "ContextControlPanel",
			"type": "ItemView (Side Panel)",
			"file": "src/ui/context-control-panel.ts",
			"description": "Provides controls for model selection, temperature, and context settings (Dynamic, Full Note, Custom). Features a `TextArea` for custom context with `[[wikilink]]` autocompletion support via `WikilinkSuggestModal`."
		},
		"modals": [
			{
				"name": "ModelSelectionModal",
				"file": "src/ui/modals/ModelSelectionModal.ts",
				"description": "A performant modal for browsing all available models. Implements a virtualized list to handle hundreds of models smoothly. Includes filtering by provider, text search, a favorites system, and a refresh mechanism."
			},
			{
				"name": "CustomPromptModal",
				"file": "src/ui/modals/custom-prompt-modal.ts",
				"description": "An ad-hoc prompt entry modal for text generation. Features a 'Modular Prompt Constructor' allowing users to insert and combine pre-saved generation prompts."
			},
			{
				"name": "PromptPaletteModal",
				"file": "src/ui/modals/prompt-palette.ts",
				"description": "An Obsidian `SuggestModal` for quickly selecting a transformation or generation prompt from a list."
			},
			{
				"name": "CustomProviderModal",
				"file": "src/ui/modals/CustomProviderModal.ts",
				"description": "A form for adding or editing `CustomProvider` configurations. Includes quick-setup buttons for common services and performs a connection test on save."
			},
			{
				"name": "WikilinkSuggestModal",
				"file": "src/ui/modals/wikilink-suggest-modal.ts",
				"description": "A `SuggestModal` triggered by typing `[[` in the custom context text area, for finding and inserting note links."
			},
			{
				"name": "SingleInputModal",
				"file": "src/ui/modals/single-input-modal.ts",
				"description": "A generic modal for getting a single line of text from the user, used for naming new knowledge graphs."
			}
		],
		"settingsTab": {
			"name": "TextTransformerSettingsMenu",
			"file": "src/ui/settings.ts",
			"description": "A tabbed settings interface for comprehensive configuration.",
			"tabs": {
				"prompts": "Manage transformation and generation prompts (enable/disable, add, edit, delete).",
				"providers": "Manage custom AI providers (add, edit, delete, enable/disable).",
				"params": "Configure global LLM parameters (`max_tokens`) and features (`graphAssetPath`)."
			}
		},
		"styling": {
			"file": "styles.css",
			"strategy": "Uses CSS variables for adaptive dark/light theme support. Styles are organized by component/feature. Defines distinct visual states for suggestions (`.text-transformer-added`, `.text-transformer-removed`) and their active/focused counterparts (`-active`)."
		}
	},
	"editorIntegration": {
		"suggestionEngine": {
			"creation": {
				"file": "src/lib/core/textTransformer.ts (`applyTransformationAsSuggestions`)",
				"library": "`diffWordsWithSpace` from the `diff` package.",
				"process": "The original text and the AI's response are diffed. The resulting `added` and `removed` parts are converted into an array of `SuggestionMark` objects. Special handling exists for newlines to create distinct marks for them."
			},
			"stateStorage": {
				"file": "src/lib/editor/suggestion-state.ts",
				"mechanism": "A CodeMirror `StateField` (`suggestionStateField`) stores the array of `SuggestionMark`s. Changes are dispatched via `StateEffect`s (`setSuggestionsEffect`, `resolveSuggestionEffect`, `clearAllSuggestionsEffect`)."
			},
			"rendering": {
				"file": "src/lib/editor/suggestion-state.ts",
				"mechanism": "A CodeMirror `ViewPlugin` (`SuggestionViewPluginClass`) reads the `suggestionStateField` and creates a `DecorationSet`. 'Added' text is rendered as a `WidgetType` (ghost text). 'Removed' text is rendered as a `Decoration.mark` (strikethrough). Active suggestions receive additional CSS classes for highlighting."
			}
		},
		"suggestionLifecycle": {
			"file": "src/lib/editor/suggestion-handler.ts",
			"description": "Implements the logic for all suggestion-related commands.",
			"commands": {
				"focus": "`focusNextSuggestionCM6`, `focusPreviousSuggestionCM6` - Find the next/previous mark and move the editor cursor and viewport.",
				"resolveSingle": "`resolveNextSuggestionCM6` - Resolves the suggestion at or after the cursor. Requires a double-tap: first to focus, second to resolve.",
				"resolveBulk": "`resolveSuggestionsInSelectionCM6` - Resolves all suggestions within the current selection or paragraph. Includes logic to navigate to the next/previous paragraph with suggestions if the current one is empty.",
				"clearAll": "`clearAllActiveSuggestionsCM6` - Rejects and removes all suggestions from the document."
			},
			"cursorManagement": "Resolution functions carefully calculate the final cursor position by mapping the original mark positions through a `ChangeSet` to account for document modifications."
		}
	},
	"features": [
		{
			"name": "Context-Aware Text Transformation",
			"description": "Applies a user-selected prompt to the current text selection or paragraph.",
			"workflow": "User triggers command -> `PromptPaletteModal` -> `textTransformerTextCM6` -> `gatherContextForAI` -> `fetchAiTransformation` -> `applyTransformationAsSuggestions` -> Suggestions rendered by `ViewPlugin`."
		},
		{
			"name": "Context-Aware Text Generation",
			"description": "Generates text at the cursor based on an ad-hoc prompt and surrounding context.",
			"workflow": "User triggers command -> `PromptPaletteModal` (for prompt blocks) -> `CustomPromptModal` -> `generateTextAndApplyAsSuggestionCM6` -> `gatherContextForAI` -> API call -> Suggestions created and rendered."
		},
		{
			"name": "Knowledge Graph Generation",
			"description": "Analyzes context to generate an Obsidian Canvas file representing a knowledge graph.",
			"workflow": "User triggers command -> `generateGraphAndCreateCanvas` -> `promptForBaseName` -> `gatherContextForAI` -> `fetchAndValidateGraphData` (uses `buildGraphPrompt`) -> `calculateLayout` (using `d3-force`) -> `constructCanvasJson` -> `app.vault.create`."
		},
		{
			"name": "Dynamic Model & Provider Management",
			"description": "Allows users to configure and switch between hundreds of models from various local and remote providers.",
			"workflow": "User configures providers in Settings -> `ModelService` fetches models from enabled providers (with caching) -> `ModelSelectionModal` displays models -> User selection updates `settings.selectedModelId`."
		},
		"Granular Suggestion Management",
		"Comprehensive Prompt Management"
	],
	"commands": [
		{ "id": "open-context-control-panel", "name": "Open AI Context Control Panel" },
		{
			"id": "generate-text-with-ad-hoc-prompt-suggestion",
			"name": "Prompt Based Context Aware Generation at Cursor"
		},
		{ "id": "generate-knowledge-graph", "name": "Generate knowledge graph" },
		{ "id": "textTransformer-selection-paragraph", "name": "Transform selection/paragraph" },
		{ "id": "accept-suggestions-in-text", "name": "Accept suggestions in selection/paragraph" },
		{ "id": "reject-suggestions-in-text", "name": "Reject suggestions in selection/paragraph" },
		{ "id": "accept-next-suggestion", "name": "Accept next suggestion" },
		{ "id": "reject-next-suggestion", "name": "Reject next suggestion" },
		{ "id": "clear-all-suggestions", "name": "Clear all active suggestions (reject all)" },
		{ "id": "focus-next-suggestion", "name": "Focus next suggestion" },
		{ "id": "focus-previous-suggestion", "name": "Focus previous suggestion" }
	]
}
